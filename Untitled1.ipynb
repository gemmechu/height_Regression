{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from albumentations import (HorizontalFlip, ShiftScaleRotate, Normalize, Resize, Compose, GaussNoise)\n",
    "from albumentations.pytorch import ToTensor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import random\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import os\n",
    "import time\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "np.random.seed(seed)\n",
    "# torch.cuda.manual_seed(seed)\n",
    "# torch.manual_seed(seed)\n",
    "# torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean, std=(0.485, 0.456, 0.406),(0.229, 0.224, 0.225)\n",
    "def get_transform(phase,mean,std):\n",
    "    list_trans=[]\n",
    "    if phase=='train':\n",
    "        list_trans.extend([HorizontalFlip(p=0.5)])\n",
    "    \n",
    "    list_trans.extend([Resize(width=224,height=224),Normalize(mean=mean,std=std, p=1), ToTensor()])  #normalizing the data & then converting to tensors\n",
    "    list_trans=Compose(list_trans)\n",
    "    return list_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self,content,mean,std,phase):\n",
    "        self.content = content\n",
    "        self.std=std\n",
    "        self.phase=phase\n",
    "        self.transform=get_transform(phase,mean,std)\n",
    "    def __getitem__(self, idx):\n",
    "        line=self.content[idx].split(',')\n",
    "        height = torch.tensor(float(line[1]))\n",
    "#         print('height: ', height)\n",
    "        img_path= '../DOH/dataset/' + line[0]\n",
    "#         print(img_path)\n",
    "        img=cv2.imread(img_path)\n",
    "        \n",
    "        augmentation=self.transform(image=img)\n",
    "        img_aug=augmentation['image']                           #[3,128,128] type:Tensor\n",
    "        \n",
    "        return img_aug, height\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.content)\n",
    "file_dir  = 'img_height.txt'   \n",
    "with open (file_dir, 'r') as f: \n",
    "        content = f.readlines()\n",
    "        content = [x.strip('\\n') for x in content]\n",
    "# dataset = MyDataset(content,mean,std,'train')\n",
    "# train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - 50, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyDataloader(content,mean,std,phase,batch_size):\n",
    "    df_train,df_valid=train_test_split(content, test_size=0.2, random_state=69)\n",
    "    df = df_train if phase=='train' else df_valid\n",
    "    dataset=MyDataset(content, mean, std, phase)\n",
    "    print(dataset.content)\n",
    "    dataloader=DataLoader(dataset, batch_size=batch_size, pin_memory= False)\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[-0.4911, -0.4911, -0.4911,  ...,  1.0331,  1.0331,  1.2728],\n",
       "           [-0.4911, -0.4911, -0.4911,  ...,  1.0331,  1.0331,  1.2728],\n",
       "           [-0.4739, -0.4739, -0.4739,  ...,  1.0502,  1.0502,  1.2899],\n",
       "           ...,\n",
       "           [-0.1314, -0.1314, -0.1314,  ..., -1.0562, -1.2788, -1.1589],\n",
       "           [-0.1999, -0.1486, -0.1486,  ..., -0.4739, -0.6965, -1.0390],\n",
       "           [-0.1999, -0.1486, -0.1486,  ..., -0.1314, -0.3541, -0.6281]],\n",
       " \n",
       "          [[-0.2150, -0.2150, -0.2150,  ...,  1.2031,  1.2031,  1.4482],\n",
       "           [-0.2150, -0.2150, -0.2150,  ...,  1.2031,  1.2031,  1.4482],\n",
       "           [-0.1975, -0.1975, -0.1975,  ...,  1.2206,  1.2206,  1.4657],\n",
       "           ...,\n",
       "           [-0.0924, -0.0924, -0.0924,  ..., -0.4251, -0.3725,  0.0301],\n",
       "           [-0.1625, -0.1099, -0.1099,  ..., -0.5126, -0.4601, -0.5126],\n",
       "           [-0.1625, -0.1099, -0.1099,  ..., -0.4251, -0.3901, -0.3725]],\n",
       " \n",
       "          [[ 0.1825,  0.1825,  0.1825,  ...,  1.4897,  1.4897,  1.7337],\n",
       "           [ 0.1825,  0.1825,  0.1825,  ...,  1.4897,  1.4897,  1.7337],\n",
       "           [ 0.1999,  0.1999,  0.1999,  ...,  1.5071,  1.5071,  1.7511],\n",
       "           ...,\n",
       "           [ 0.2871,  0.2871,  0.2871,  ..., -0.6018, -0.6018, -0.2358],\n",
       "           [ 0.2173,  0.2696,  0.2696,  ..., -0.6890, -0.6890, -0.7936],\n",
       "           [ 0.2173,  0.2696,  0.2696,  ..., -0.4275, -0.4275, -0.4450]]],\n",
       " \n",
       " \n",
       "         [[[-0.4911, -0.4911, -0.4911,  ...,  1.0331,  1.0331,  1.2728],\n",
       "           [-0.4911, -0.4911, -0.4911,  ...,  1.0331,  1.0331,  1.2728],\n",
       "           [-0.4739, -0.4911, -0.4911,  ...,  1.0502,  1.0502,  1.2899],\n",
       "           ...,\n",
       "           [-0.1314, -0.1486, -0.1314,  ..., -0.9534, -1.0219, -1.0219],\n",
       "           [-0.1999, -0.1657, -0.1314,  ..., -0.5082, -0.7308, -0.9705],\n",
       "           [-0.1999, -0.1657, -0.1314,  ..., -0.3541, -0.6109, -0.9192]],\n",
       " \n",
       "          [[-0.2150, -0.2150, -0.2150,  ...,  1.2031,  1.2031,  1.4482],\n",
       "           [-0.2150, -0.2150, -0.2150,  ...,  1.2031,  1.2031,  1.4482],\n",
       "           [-0.1975, -0.2150, -0.2150,  ...,  1.2206,  1.2206,  1.4657],\n",
       "           ...,\n",
       "           [-0.0924, -0.1099, -0.0924,  ..., -0.5826, -0.3725, -0.0924],\n",
       "           [-0.1625, -0.1275, -0.0924,  ..., -0.5126, -0.4601, -0.4251],\n",
       "           [-0.1625, -0.1275, -0.0924,  ..., -0.4776, -0.4251, -0.4601]],\n",
       " \n",
       "          [[ 0.1825,  0.1825,  0.1825,  ...,  1.4897,  1.4897,  1.7337],\n",
       "           [ 0.1825,  0.1825,  0.1825,  ...,  1.4897,  1.4897,  1.7337],\n",
       "           [ 0.1999,  0.1825,  0.1825,  ...,  1.5071,  1.5071,  1.7511],\n",
       "           ...,\n",
       "           [ 0.2871,  0.2871,  0.2871,  ..., -0.7064, -0.6018, -0.4101],\n",
       "           [ 0.2173,  0.2522,  0.2871,  ..., -0.4798, -0.4973, -0.5321],\n",
       "           [ 0.2173,  0.2522,  0.2871,  ..., -0.1835, -0.2184, -0.3404]]],\n",
       " \n",
       " \n",
       "         [[[-0.4911, -0.4911, -0.4911,  ...,  1.0331,  1.0331,  1.2728],\n",
       "           [-0.4911, -0.4911, -0.4911,  ...,  1.0331,  1.0331,  1.2728],\n",
       "           [-0.4911, -0.4911, -0.4911,  ...,  1.0331,  1.0331,  1.2899],\n",
       "           ...,\n",
       "           [-0.1314, -0.1314, -0.1314,  ..., -0.7479, -0.8678, -1.0048],\n",
       "           [-0.1999, -0.1657, -0.1314,  ..., -0.3198, -0.5424, -0.7822],\n",
       "           [-0.1999, -0.1657, -0.1314,  ..., -0.3712, -0.5767, -0.8335]],\n",
       " \n",
       "          [[-0.2150, -0.2150, -0.2150,  ...,  1.2031,  1.2031,  1.4482],\n",
       "           [-0.2150, -0.2150, -0.2150,  ...,  1.2031,  1.2031,  1.4482],\n",
       "           [-0.2150, -0.2150, -0.2150,  ...,  1.2031,  1.2031,  1.4657],\n",
       "           ...,\n",
       "           [-0.0924, -0.0924, -0.0924,  ..., -0.5651, -0.4251, -0.2850],\n",
       "           [-0.1625, -0.1275, -0.0924,  ..., -0.4776, -0.4076, -0.3901],\n",
       "           [-0.1625, -0.1275, -0.0924,  ..., -0.3725, -0.3200, -0.3200]],\n",
       " \n",
       "          [[ 0.1825,  0.1825,  0.1825,  ...,  1.4897,  1.4897,  1.7337],\n",
       "           [ 0.1825,  0.1825,  0.1825,  ...,  1.4897,  1.4897,  1.7337],\n",
       "           [ 0.1825,  0.1825,  0.1825,  ...,  1.5071,  1.5071,  1.7511],\n",
       "           ...,\n",
       "           [ 0.2871,  0.2871,  0.2871,  ..., -0.7064, -0.6541, -0.5670],\n",
       "           [ 0.2173,  0.2522,  0.2871,  ..., -0.4973, -0.5321, -0.5844],\n",
       "           [ 0.2173,  0.2522,  0.2871,  ..., -0.2010, -0.2358, -0.3404]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.4911, -0.4911, -0.4911,  ...,  1.0159,  1.0159,  1.2728],\n",
       "           [-0.4911, -0.4911, -0.4911,  ...,  1.0159,  1.0159,  1.2728],\n",
       "           [-0.4739, -0.4739, -0.4739,  ...,  1.0331,  1.0331,  1.2899],\n",
       "           ...,\n",
       "           [-0.1657, -0.1486, -0.1486,  ..., -0.1657, -0.5767, -0.8849],\n",
       "           [-0.2171, -0.1314, -0.1314,  ..., -0.4054, -0.4397, -0.5596],\n",
       "           [-0.2171, -0.1314, -0.1314,  ..., -0.6109, -0.5253, -0.4911]],\n",
       " \n",
       "          [[-0.2150, -0.2150, -0.2150,  ...,  1.1856,  1.1856,  1.4482],\n",
       "           [-0.2150, -0.2150, -0.2150,  ...,  1.1856,  1.1856,  1.4482],\n",
       "           [-0.1975, -0.1975, -0.1975,  ...,  1.2031,  1.2031,  1.4657],\n",
       "           ...,\n",
       "           [-0.0924, -0.0749, -0.0749,  ..., -0.3375, -0.4951, -0.5126],\n",
       "           [-0.1450, -0.0574, -0.0574,  ..., -0.3025, -0.2850, -0.3375],\n",
       "           [-0.1450, -0.0574, -0.0574,  ..., -0.0574, -0.0749, -0.1450]],\n",
       " \n",
       "          [[ 0.1825,  0.1825,  0.1825,  ...,  1.4722,  1.4722,  1.7337],\n",
       "           [ 0.1825,  0.1825,  0.1825,  ...,  1.4722,  1.4722,  1.7337],\n",
       "           [ 0.1999,  0.1999,  0.1999,  ...,  1.5071,  1.5071,  1.7511],\n",
       "           ...,\n",
       "           [ 0.2871,  0.3045,  0.3045,  ..., -0.3230, -0.5147, -0.5670],\n",
       "           [ 0.2348,  0.3219,  0.3219,  ..., -0.3230, -0.3230, -0.3753],\n",
       "           [ 0.2348,  0.3219,  0.3219,  ..., -0.1487, -0.1487, -0.2010]]],\n",
       " \n",
       " \n",
       "         [[[-0.4911, -0.4911, -0.4911,  ...,  1.0159,  1.0159,  1.2728],\n",
       "           [-0.4911, -0.4911, -0.4911,  ...,  1.0159,  1.0159,  1.2728],\n",
       "           [-0.4739, -0.4739, -0.4739,  ...,  1.0331,  1.0331,  1.2899],\n",
       "           ...,\n",
       "           [-0.1657, -0.1486, -0.1486,  ..., -0.2171, -0.4226, -0.7137],\n",
       "           [-0.2171, -0.1314, -0.1314,  ..., -0.3369, -0.3712, -0.4568],\n",
       "           [-0.2171, -0.1314, -0.1314,  ..., -0.5424, -0.4739, -0.5596]],\n",
       " \n",
       "          [[-0.2150, -0.2150, -0.2150,  ...,  1.1856,  1.1856,  1.4482],\n",
       "           [-0.2150, -0.2150, -0.2150,  ...,  1.1856,  1.1856,  1.4482],\n",
       "           [-0.1975, -0.1975, -0.1975,  ...,  1.2031,  1.2031,  1.4657],\n",
       "           ...,\n",
       "           [-0.0924, -0.0749, -0.0749,  ..., -0.4601, -0.4076, -0.3901],\n",
       "           [-0.1450, -0.0574, -0.0574,  ..., -0.2850, -0.2850, -0.2850],\n",
       "           [-0.1450, -0.0574, -0.0574,  ..., -0.0399, -0.0574, -0.2675]],\n",
       " \n",
       "          [[ 0.1825,  0.1825,  0.1825,  ...,  1.4722,  1.4722,  1.7337],\n",
       "           [ 0.1825,  0.1825,  0.1825,  ...,  1.4722,  1.4722,  1.7337],\n",
       "           [ 0.1999,  0.1999,  0.1999,  ...,  1.5071,  1.5071,  1.7511],\n",
       "           ...,\n",
       "           [ 0.2871,  0.3045,  0.3045,  ..., -0.3753, -0.3753, -0.3927],\n",
       "           [ 0.2348,  0.3219,  0.3219,  ..., -0.2532, -0.2532, -0.2707],\n",
       "           [ 0.2348,  0.3219,  0.3219,  ..., -0.0790, -0.0790, -0.2707]]],\n",
       " \n",
       " \n",
       "         [[[ 1.2728,  1.0159,  1.0159,  ..., -0.4911, -0.4911, -0.4911],\n",
       "           [ 1.2728,  1.0159,  1.0159,  ..., -0.4911, -0.4911, -0.4911],\n",
       "           [ 1.2899,  1.0331,  1.0331,  ..., -0.4739, -0.4739, -0.4739],\n",
       "           ...,\n",
       "           [-0.7479, -0.4226, -0.1999,  ..., -0.1486, -0.1486, -0.1657],\n",
       "           [-0.5767, -0.3198, -0.1143,  ..., -0.1314, -0.1314, -0.2171],\n",
       "           [-0.7993, -0.4054, -0.1657,  ..., -0.1314, -0.1314, -0.2171]],\n",
       " \n",
       "          [[ 1.4482,  1.1856,  1.1856,  ..., -0.2150, -0.2150, -0.2150],\n",
       "           [ 1.4482,  1.1856,  1.1856,  ..., -0.2150, -0.2150, -0.2150],\n",
       "           [ 1.4657,  1.2031,  1.2031,  ..., -0.1975, -0.1975, -0.1975],\n",
       "           ...,\n",
       "           [-0.4426, -0.4251, -0.4601,  ..., -0.0749, -0.0749, -0.0924],\n",
       "           [-0.2325, -0.2850, -0.3200,  ..., -0.0574, -0.0574, -0.1450],\n",
       "           [-0.1800, -0.0574, -0.0924,  ..., -0.0574, -0.0574, -0.1450]],\n",
       " \n",
       "          [[ 1.7337,  1.4722,  1.4722,  ...,  0.1825,  0.1825,  0.1825],\n",
       "           [ 1.7337,  1.4722,  1.4722,  ...,  0.1825,  0.1825,  0.1825],\n",
       "           [ 1.7511,  1.5071,  1.5071,  ...,  0.1999,  0.1999,  0.1999],\n",
       "           ...,\n",
       "           [-0.4973, -0.4275, -0.4275,  ...,  0.3045,  0.3045,  0.2871],\n",
       "           [-0.2881, -0.2881, -0.2881,  ...,  0.3219,  0.3219,  0.2348],\n",
       "           [-0.2881, -0.1138, -0.1138,  ...,  0.3219,  0.3219,  0.2348]]]],\n",
       "        device='cpu'),\n",
       " tensor([0.3950, 0.4040, 0.4040, 0.4020, 0.4020, 0.4000, 0.4000, 0.4000])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader = MyDataloader(content,mean,std,'train',8)\n",
    "next(iter(dataloader))\n",
    "# iter(dataloader.next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.resnet34(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    # Replace the last fully-connected layer\n",
    "    # Parameters of newly constructed modules have requires_grad=True by default\n",
    "model.fc = torch.nn.Linear(512, 1) # assuming that the fc7 layer has 512 neurons\n",
    "model\n",
    "# model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        layers = list(models.resnet34(pretrained=True).children())[:-2]\n",
    "        layers += [AdaptiveConcatPool2d(), Flatten()]\n",
    "        layers += [nn.BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)]\n",
    "        layers += [nn.Dropout(p=0.50)]\n",
    "        layers += [nn.Linear(1024, 512, bias=True), nn.ReLU(inplace=True)]\n",
    "        layers += [nn.BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)]\n",
    "        layers += [nn.Dropout(p=0.50)]\n",
    "        layers += [nn.Linear(512, 16, bias=True), nn.ReLU(inplace=True)]\n",
    "        layers += [nn.Linear(16,1)]\n",
    "        self.mymodel = nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.mymodel(x).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (mymodel): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): AdaptiveConcatPool2d(\n",
       "      (ap): AdaptiveAvgPool2d(output_size=1)\n",
       "      (mp): AdaptiveMaxPool2d(output_size=1)\n",
       "    )\n",
       "    (9): Flatten()\n",
       "    (10): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): Dropout(p=0.5, inplace=False)\n",
       "    (12): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (15): Dropout(p=0.5, inplace=False)\n",
       "    (16): Linear(in_features=512, out_features=16, bias=True)\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Linear(in_features=16, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred, target):\n",
    "    diffrence = abs(pred - target)\n",
    "    boolean_diff = diffrence >0.15\n",
    "    accu = torch.sum(boolean_diff == True)\n",
    "    accu = 100* accu//len(pred)\n",
    "    return accu\n",
    "def epoch_log(phase, epoch, epoch_loss,epoch_correct, start):\n",
    "    '''logging the metrics at the end of an epoch'''\n",
    "#     dices= measure.get_metrics()    \n",
    "#     dice= dices                       \n",
    "    print(\"Loss: %0.4f |accuracy: %0.4f\" % (epoch_loss, epoch_correct))\n",
    "#     print(\"Loss: %0.4f \" % (epoch_loss))\n",
    "#     return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self,model):\n",
    "#         self.num_workers=0\n",
    "        self.batch_size={'train':8, 'val':8}\n",
    "        self.accumulation_steps=1\n",
    "        self.lr=10e-4\n",
    "        self.num_epochs=10\n",
    "        self.phases=['train','val']\n",
    "        self.best_loss=float('inf')\n",
    "        self.device=torch.device(\"cuda:0\")\n",
    "        torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "        self.net=model.to(self.device)\n",
    "#         cudnn.benchmark= False\n",
    "        \n",
    "        self.criterion=torch.nn.MSELoss()\n",
    "        self.optimizer=optim.Adam(self.net.parameters(),lr=self.lr)\n",
    "        self.scheduler=ReduceLROnPlateau(self.optimizer,mode='min',patience=3, verbose=True)\n",
    "        \n",
    "        self.dataloaders={phase: MyDataloader(content, mean, std,\n",
    "                                               phase=phase,batch_size=self.batch_size[phase]) for phase in self.phases}\n",
    "\n",
    "        \n",
    "    def forward(self, input_img, target):\n",
    "        input_img=input_img.to(self.device)\n",
    "#         print('shape_img', inp_images.shape)\n",
    "        target =target.to(self.device)\n",
    "#         print('target,', target)\n",
    "        pred =self.net(input_img)\n",
    "#         print('pred: ', pred)\n",
    "#         print('mean: ', tar_mask.mean())\n",
    "#         print('pred_shape', pred_mask.shape)\n",
    "#         print('tar_mask', tar_mask.shape)\n",
    "#         a = collections.Counter(pred_mask[0].to('cpu').detach().numpy().flatten())\n",
    "#         print('counter: ',a)\n",
    "        loss=self.criterion(pred,target)\n",
    "        return loss, pred\n",
    "    \n",
    "    def iterate(self, epoch, phase):\n",
    "#         measure=Scores(phase, epoch)\n",
    "        start=time.strftime(\"%H:%M:%S\")\n",
    "        print (f\"Starting epoch: {epoch} | phase:{phase} | ðŸ™Š':{start}\")\n",
    "        batch_size=self.batch_size[phase]\n",
    "        self.net.train(phase==\"train\")\n",
    "        dataloader=self.dataloaders[phase]\n",
    "        running_loss=0.0\n",
    "        correct= 0.0\n",
    "        total_batches=len(dataloader)\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        cnt = 0\n",
    "        for itr,batch in enumerate(dataloader):\n",
    "            images,target =batch\n",
    "#             print('images sahpe ',images.shape)\n",
    "#             print('target shape', target.shape)\n",
    "#             print('target: ', target)\n",
    "            \n",
    "            loss, pred=self.forward(images,target)\n",
    "#             print('loss: ', loss)\n",
    "#             print('pred: ', pred)\n",
    "            loss=loss/self.accumulation_steps\n",
    "            if phase=='train':\n",
    "                loss.backward()\n",
    "                if (itr+1) % self.accumulation_steps ==0:\n",
    "                    self.optimizer.step()\n",
    "                    self.optimizer.zero_grad()\n",
    "            running_loss+=loss.item()\n",
    "#             print('pred', pred)\n",
    "#             print('target', target)\n",
    "            cnt += 1\n",
    "            correct += accuracy(pred, target)\n",
    "#             pred=pred.detach().cpu()\n",
    "#             measure.update(mask_target,pred_mask)\n",
    "        epoch_loss=(running_loss*self.accumulation_steps)/total_batches\n",
    "#         print('correct: ', correct)\n",
    "        print('cnt: ', cnt)\n",
    "        print('total_batches: ',total_batches)\n",
    "        epoch_correct  = float((correct/cnt))\n",
    "#         print('epoch_correct: ', epoch_correct)\n",
    "        epoch_log(phase, epoch, epoch_loss, epoch_correct,start)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        return epoch_loss\n",
    "    def start(self):\n",
    "        \n",
    "        for epoch in range (self.num_epochs):\n",
    "            self.iterate(epoch,\"train\")\n",
    "            state = {\n",
    "                \"epoch\": epoch,\n",
    "                \"best_loss\": self.best_loss,\n",
    "                \"state_dict\": self.net.state_dict(),\n",
    "                \"optimizer\": self.optimizer.state_dict(),\n",
    "            }\n",
    "            with torch.no_grad():\n",
    "                val_loss=self.iterate(epoch,\"val\")\n",
    "                self.scheduler.step(val_loss)\n",
    "            if val_loss < self.best_loss:\n",
    "                print(\"******** New optimal found, saving state ********\")\n",
    "                state[\"best_loss\"] = self.best_loss = val_loss\n",
    "                torch.save(state, \"./model_office.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch: 0 | phase:train | ðŸ™Š':09:22:18\n",
      "cnt:  2607\n",
      "total_batches:  2607\n",
      "Loss: 0.0239 |accuracy: 23.6874\n",
      "Starting epoch: 0 | phase:val | ðŸ™Š':09:27:53\n",
      "cnt:  2607\n",
      "total_batches:  2607\n",
      "Loss: 0.3817 |accuracy: 83.0422\n",
      "******** New optimal found, saving state ********\n",
      "Starting epoch: 1 | phase:train | ðŸ™Š':09:31:41\n",
      "cnt:  2607\n",
      "total_batches:  2607\n",
      "Loss: 0.0146 |accuracy: 17.4507\n",
      "Starting epoch: 1 | phase:val | ðŸ™Š':09:37:14\n",
      "cnt:  2607\n",
      "total_batches:  2607\n",
      "Loss: 0.0248 |accuracy: 31.9003\n",
      "******** New optimal found, saving state ********\n",
      "Starting epoch: 2 | phase:train | ðŸ™Š':09:41:01\n",
      "cnt:  2607\n",
      "total_batches:  2607\n",
      "Loss: 0.0149 |accuracy: 18.1841\n",
      "Starting epoch: 2 | phase:val | ðŸ™Š':09:46:35\n",
      "cnt:  2607\n",
      "total_batches:  2607\n",
      "Loss: 0.0237 |accuracy: 34.8005\n",
      "******** New optimal found, saving state ********\n",
      "Starting epoch: 3 | phase:train | ðŸ™Š':09:50:23\n",
      "cnt:  2607\n",
      "total_batches:  2607\n",
      "Loss: 0.0150 |accuracy: 18.3157\n",
      "Starting epoch: 3 | phase:val | ðŸ™Š':09:55:58\n",
      "cnt:  2607\n",
      "total_batches:  2607\n",
      "Loss: 0.0229 |accuracy: 32.9198\n",
      "******** New optimal found, saving state ********\n",
      "Starting epoch: 4 | phase:train | ðŸ™Š':09:59:46\n",
      "cnt:  2607\n",
      "total_batches:  2607\n",
      "Loss: 0.0150 |accuracy: 18.2202\n",
      "Starting epoch: 4 | phase:val | ðŸ™Š':10:05:21\n",
      "cnt:  2607\n",
      "total_batches:  2607\n",
      "Loss: 0.0231 |accuracy: 32.1477\n",
      "Starting epoch: 5 | phase:train | ðŸ™Š':10:09:08\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-05f46443fc03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_trainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-40a64d7fb49b>\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             state = {\n\u001b[1;32m     89\u001b[0m                 \u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-40a64d7fb49b>\u001b[0m in \u001b[0;36miterate\u001b[0;34m(self, epoch, phase)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mcnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mitr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m#             print('images sahpe ',images.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-7ed475312850>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mimg_path\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'../DOH/dataset/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#         print(img_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0maugmentation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_trainer = Trainer(model)\n",
    "model_trainer.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "content = []\n",
    "for item in os.listdir('output/gt'):\n",
    "    if item.endswith('.jpg'):\n",
    "        content.append(item)\n",
    "len(content)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\n",
    "model.load_state_dict(state[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['living/K5iHe2mql_s/shot_10/000001.jpg,0.395',\n",
       " 'living/K5iHe2mql_s/shot_10/000002.jpg,0.404',\n",
       " 'living/K5iHe2mql_s/shot_10/000003.jpg,0.404',\n",
       " 'living/K5iHe2mql_s/shot_10/000008.jpg,0.402',\n",
       " 'living/K5iHe2mql_s/shot_10/000014.jpg,0.402',\n",
       " 'living/K5iHe2mql_s/shot_10/000015.jpg,0.4',\n",
       " 'living/K5iHe2mql_s/shot_10/000016.jpg,0.4',\n",
       " 'living/K5iHe2mql_s/shot_10/000017.jpg,0.4',\n",
       " 'living/K5iHe2mql_s/shot_10/000018.jpg,0.4',\n",
       " 'living/K5iHe2mql_s/shot_10/000021.jpg,0.40549999999999997']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tr>\n",
      "<td> <img src= \"src/median/kitchen_shzdfkUmdDc_shot_17_5.jpg\" style=\"width: 400px;\"/><br>kitchen_shzdfkUmdDc_shot_17_5.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/kitchen_shzdfkUmdDc_shot_17_5.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/kitchen_shzdfkUmdDc_shot_17_5.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/kitchen_PyiqO_aS3lY_shot_1_2.jpg\" style=\"width: 400px;\"/><br>kitchen_PyiqO_aS3lY_shot_1_2.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/kitchen_PyiqO_aS3lY_shot_1_2.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/kitchen_PyiqO_aS3lY_shot_1_2.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/kitchen_eAjrEH-n8IM_shot_10_100.jpg\" style=\"width: 400px;\"/><br>kitchen_eAjrEH-n8IM_shot_10_100.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/kitchen_eAjrEH-n8IM_shot_10_100.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/kitchen_eAjrEH-n8IM_shot_10_100.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/kitchen_vCyNhb0PvNI_shot_12_3.jpg\" style=\"width: 400px;\"/><br>kitchen_vCyNhb0PvNI_shot_12_3.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/kitchen_vCyNhb0PvNI_shot_12_3.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/kitchen_vCyNhb0PvNI_shot_12_3.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/washroom_bedroom_bathroom_NBh7jiiL_zE_shot_0_12.jpg\" style=\"width: 400px;\"/><br>washroom_bedroom_bathroom_NBh7jiiL_zE_shot_0_12.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/washroom_bedroom_bathroom_NBh7jiiL_zE_shot_0_12.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/washroom_bedroom_bathroom_NBh7jiiL_zE_shot_0_12.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/washroom_bedroom_bathroom_xnJiqGkf-Cs_shot_0_1.jpg\" style=\"width: 400px;\"/><br>washroom_bedroom_bathroom_xnJiqGkf-Cs_shot_0_1.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/washroom_bedroom_bathroom_xnJiqGkf-Cs_shot_0_1.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/washroom_bedroom_bathroom_xnJiqGkf-Cs_shot_0_1.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/washroom_bedroom_bathroom_1Jzz-YFcXfk_shot_16_0.jpg\" style=\"width: 400px;\"/><br>washroom_bedroom_bathroom_1Jzz-YFcXfk_shot_16_0.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/washroom_bedroom_bathroom_1Jzz-YFcXfk_shot_16_0.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/washroom_bedroom_bathroom_1Jzz-YFcXfk_shot_16_0.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/washroom_bedroom_bathroom_PSxxztopXXM_shot_8_0.jpg\" style=\"width: 400px;\"/><br>washroom_bedroom_bathroom_PSxxztopXXM_shot_8_0.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/washroom_bedroom_bathroom_PSxxztopXXM_shot_8_0.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/washroom_bedroom_bathroom_PSxxztopXXM_shot_8_0.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/DIY_outdoors_F536sIznPE8_shot_8_15.jpg\" style=\"width: 400px;\"/><br>DIY_outdoors_F536sIznPE8_shot_8_15.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/DIY_outdoors_F536sIznPE8_shot_8_15.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/DIY_outdoors_F536sIznPE8_shot_8_15.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/kitchen_NFQHTO2SuFU_shot_9_2.jpg\" style=\"width: 400px;\"/><br>kitchen_NFQHTO2SuFU_shot_9_2.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/kitchen_NFQHTO2SuFU_shot_9_2.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/kitchen_NFQHTO2SuFU_shot_9_2.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/kitchen_50dVWkWVJfE_shot_30_0.jpg\" style=\"width: 400px;\"/><br>kitchen_50dVWkWVJfE_shot_30_0.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/kitchen_50dVWkWVJfE_shot_30_0.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/kitchen_50dVWkWVJfE_shot_30_0.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/washroom_bedroom_bathroom_eAA14wGr4Rc_shot_19_3.jpg\" style=\"width: 400px;\"/><br>washroom_bedroom_bathroom_eAA14wGr4Rc_shot_19_3.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/washroom_bedroom_bathroom_eAA14wGr4Rc_shot_19_3.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/washroom_bedroom_bathroom_eAA14wGr4Rc_shot_19_3.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/washroom_bedroom_bathroom_UDpBlcCUgUY_shot_7_1.jpg\" style=\"width: 400px;\"/><br>washroom_bedroom_bathroom_UDpBlcCUgUY_shot_7_1.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/washroom_bedroom_bathroom_UDpBlcCUgUY_shot_7_1.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/washroom_bedroom_bathroom_UDpBlcCUgUY_shot_7_1.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/music_m511X-xLad8_shot_1_6.jpg\" style=\"width: 400px;\"/><br>music_m511X-xLad8_shot_1_6.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/music_m511X-xLad8_shot_1_6.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/music_m511X-xLad8_shot_1_6.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/kitchen_NFQHTO2SuFU_shot_2_4.jpg\" style=\"width: 400px;\"/><br>kitchen_NFQHTO2SuFU_shot_2_4.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/kitchen_NFQHTO2SuFU_shot_2_4.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/kitchen_NFQHTO2SuFU_shot_2_4.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/athletics_DYiytA9S14o_shot_1_10.jpg\" style=\"width: 400px;\"/><br>athletics_DYiytA9S14o_shot_1_10.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/athletics_DYiytA9S14o_shot_1_10.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/athletics_DYiytA9S14o_shot_1_10.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/athletics_zLPhkfJpQCI_shot_2_206.jpg\" style=\"width: 400px;\"/><br>athletics_zLPhkfJpQCI_shot_2_206.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/athletics_zLPhkfJpQCI_shot_2_206.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/athletics_zLPhkfJpQCI_shot_2_206.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/music_1spUISjktz4_shot_60_3.jpg\" style=\"width: 400px;\"/><br>music_1spUISjktz4_shot_60_3.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/music_1spUISjktz4_shot_60_3.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/music_1spUISjktz4_shot_60_3.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/kitchen_1nKMsrhbOCc_shot_19_2.jpg\" style=\"width: 400px;\"/><br>kitchen_1nKMsrhbOCc_shot_19_2.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/kitchen_1nKMsrhbOCc_shot_19_2.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/kitchen_1nKMsrhbOCc_shot_19_2.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/kitchen_8kRHDJ-SqPY_shot_12_6.jpg\" style=\"width: 400px;\"/><br>kitchen_8kRHDJ-SqPY_shot_12_6.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/kitchen_8kRHDJ-SqPY_shot_12_6.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/kitchen_8kRHDJ-SqPY_shot_12_6.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/kitchen_wKez2wtIWEE_shot_54_0.jpg\" style=\"width: 400px;\"/><br>kitchen_wKez2wtIWEE_shot_54_0.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/kitchen_wKez2wtIWEE_shot_54_0.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/kitchen_wKez2wtIWEE_shot_54_0.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/kitchen_gckFcR27SXE_shot_41_14.jpg\" style=\"width: 400px;\"/><br>kitchen_gckFcR27SXE_shot_41_14.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/kitchen_gckFcR27SXE_shot_41_14.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/kitchen_gckFcR27SXE_shot_41_14.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/washroom_bedroom_bathroom_oxzZ3hZLWOk_shot_15_7.jpg\" style=\"width: 400px;\"/><br>washroom_bedroom_bathroom_oxzZ3hZLWOk_shot_15_7.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/washroom_bedroom_bathroom_oxzZ3hZLWOk_shot_15_7.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/washroom_bedroom_bathroom_oxzZ3hZLWOk_shot_15_7.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/kitchen_CLcz1xl8o60_shot_3_3.jpg\" style=\"width: 400px;\"/><br>kitchen_CLcz1xl8o60_shot_3_3.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/kitchen_CLcz1xl8o60_shot_3_3.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/kitchen_CLcz1xl8o60_shot_3_3.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/kitchen_NFQHTO2SuFU_shot_4_0.jpg\" style=\"width: 400px;\"/><br>kitchen_NFQHTO2SuFU_shot_4_0.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/kitchen_NFQHTO2SuFU_shot_4_0.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/kitchen_NFQHTO2SuFU_shot_4_0.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/kitchen_jO-CcZN9qAM_shot_42_10.jpg\" style=\"width: 400px;\"/><br>kitchen_jO-CcZN9qAM_shot_42_10.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/kitchen_jO-CcZN9qAM_shot_42_10.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/kitchen_jO-CcZN9qAM_shot_42_10.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/kitchen_eAjrEH-n8IM_shot_10_31.jpg\" style=\"width: 400px;\"/><br>kitchen_eAjrEH-n8IM_shot_10_31.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/kitchen_eAjrEH-n8IM_shot_10_31.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/kitchen_eAjrEH-n8IM_shot_10_31.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/kitchen_NdgDno6sViY_shot_52_2.jpg\" style=\"width: 400px;\"/><br>kitchen_NdgDno6sViY_shot_52_2.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/kitchen_NdgDno6sViY_shot_52_2.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/kitchen_NdgDno6sViY_shot_52_2.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/kitchen_VjwiarnpkeM_shot_3_6.jpg\" style=\"width: 400px;\"/><br>kitchen_VjwiarnpkeM_shot_3_6.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/kitchen_VjwiarnpkeM_shot_3_6.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/kitchen_VjwiarnpkeM_shot_3_6.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/DIY_outdoors_QtL5a-rj100_shot_5_1.jpg\" style=\"width: 400px;\"/><br>DIY_outdoors_QtL5a-rj100_shot_5_1.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/DIY_outdoors_QtL5a-rj100_shot_5_1.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/DIY_outdoors_QtL5a-rj100_shot_5_1.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/kitchen_sbOWB4hUWdI_shot_6_1.jpg\" style=\"width: 400px;\"/><br>kitchen_sbOWB4hUWdI_shot_6_1.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/kitchen_sbOWB4hUWdI_shot_6_1.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/kitchen_sbOWB4hUWdI_shot_6_1.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/washroom_bedroom_bathroom_qZFi3lTylwA_shot_41_0.jpg\" style=\"width: 400px;\"/><br>washroom_bedroom_bathroom_qZFi3lTylwA_shot_41_0.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/washroom_bedroom_bathroom_qZFi3lTylwA_shot_41_0.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/washroom_bedroom_bathroom_qZFi3lTylwA_shot_41_0.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/music_aUXSGn4ZVL4_shot_2_38.jpg\" style=\"width: 400px;\"/><br>music_aUXSGn4ZVL4_shot_2_38.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/music_aUXSGn4ZVL4_shot_2_38.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/music_aUXSGn4ZVL4_shot_2_38.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/kitchen_YErVKBuv5pg_shot_19_1.jpg\" style=\"width: 400px;\"/><br>kitchen_YErVKBuv5pg_shot_19_1.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/kitchen_YErVKBuv5pg_shot_19_1.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/kitchen_YErVKBuv5pg_shot_19_1.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/washroom_bedroom_bathroom_MZH8-aNLR3c_shot_17_5.jpg\" style=\"width: 400px;\"/><br>washroom_bedroom_bathroom_MZH8-aNLR3c_shot_17_5.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/washroom_bedroom_bathroom_MZH8-aNLR3c_shot_17_5.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/washroom_bedroom_bathroom_MZH8-aNLR3c_shot_17_5.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/washroom_bedroom_bathroom_0ZWSzx8U0Ks_shot_61_0.jpg\" style=\"width: 400px;\"/><br>washroom_bedroom_bathroom_0ZWSzx8U0Ks_shot_61_0.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/washroom_bedroom_bathroom_0ZWSzx8U0Ks_shot_61_0.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/washroom_bedroom_bathroom_0ZWSzx8U0Ks_shot_61_0.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/kitchen_yr-_Riv68uM_shot_13_3.jpg\" style=\"width: 400px;\"/><br>kitchen_yr-_Riv68uM_shot_13_3.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/kitchen_yr-_Riv68uM_shot_13_3.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/kitchen_yr-_Riv68uM_shot_13_3.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/washroom_bedroom_bathroom_xltALgcUsTY_shot_11_4.jpg\" style=\"width: 400px;\"/><br>washroom_bedroom_bathroom_xltALgcUsTY_shot_11_4.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/washroom_bedroom_bathroom_xltALgcUsTY_shot_11_4.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/washroom_bedroom_bathroom_xltALgcUsTY_shot_11_4.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/kitchen_V7TbcdQkp7Q_shot_7_2.jpg\" style=\"width: 400px;\"/><br>kitchen_V7TbcdQkp7Q_shot_7_2.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/kitchen_V7TbcdQkp7Q_shot_7_2.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/kitchen_V7TbcdQkp7Q_shot_7_2.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/kitchen__5U7SYI0DFQ_shot_1_20.jpg\" style=\"width: 400px;\"/><br>kitchen__5U7SYI0DFQ_shot_1_20.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/kitchen__5U7SYI0DFQ_shot_1_20.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/kitchen__5U7SYI0DFQ_shot_1_20.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/kitchen_QSb3juBp-a0_shot_14_3.jpg\" style=\"width: 400px;\"/><br>kitchen_QSb3juBp-a0_shot_14_3.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/kitchen_QSb3juBp-a0_shot_14_3.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/kitchen_QSb3juBp-a0_shot_14_3.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/washroom_bedroom_bathroom_jPbnbHKPuoE_shot_69_7.jpg\" style=\"width: 400px;\"/><br>washroom_bedroom_bathroom_jPbnbHKPuoE_shot_69_7.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/washroom_bedroom_bathroom_jPbnbHKPuoE_shot_69_7.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/washroom_bedroom_bathroom_jPbnbHKPuoE_shot_69_7.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/kitchen_F6GAGKXP2zU_shot_1_11.jpg\" style=\"width: 400px;\"/><br>kitchen_F6GAGKXP2zU_shot_1_11.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/kitchen_F6GAGKXP2zU_shot_1_11.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/kitchen_F6GAGKXP2zU_shot_1_11.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/kitchen_hojP6U5CfMg_shot_14_1.jpg\" style=\"width: 400px;\"/><br>kitchen_hojP6U5CfMg_shot_14_1.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/kitchen_hojP6U5CfMg_shot_14_1.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/kitchen_hojP6U5CfMg_shot_14_1.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/music_aUXSGn4ZVL4_shot_2_30.jpg\" style=\"width: 400px;\"/><br>music_aUXSGn4ZVL4_shot_2_30.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/music_aUXSGn4ZVL4_shot_2_30.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/music_aUXSGn4ZVL4_shot_2_30.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/kitchen_7qO_Q_PQnAo_shot_0_15.jpg\" style=\"width: 400px;\"/><br>kitchen_7qO_Q_PQnAo_shot_0_15.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/kitchen_7qO_Q_PQnAo_shot_0_15.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/kitchen_7qO_Q_PQnAo_shot_0_15.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/music_tigw7-MBERk_shot_186_0.jpg\" style=\"width: 400px;\"/><br>music_tigw7-MBERk_shot_186_0.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/music_tigw7-MBERk_shot_186_0.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/music_tigw7-MBERk_shot_186_0.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/athletics_zLPhkfJpQCI_shot_1_11.jpg\" style=\"width: 400px;\"/><br>athletics_zLPhkfJpQCI_shot_1_11.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/athletics_zLPhkfJpQCI_shot_1_11.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/athletics_zLPhkfJpQCI_shot_1_11.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/kitchen_eAjrEH-n8IM_shot_10_126.jpg\" style=\"width: 400px;\"/><br>kitchen_eAjrEH-n8IM_shot_10_126.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/kitchen_eAjrEH-n8IM_shot_10_126.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/kitchen_eAjrEH-n8IM_shot_10_126.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/washroom_bedroom_bathroom_Nw5v49AmVKY_shot_5_8.jpg\" style=\"width: 400px;\"/><br>washroom_bedroom_bathroom_Nw5v49AmVKY_shot_5_8.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/washroom_bedroom_bathroom_Nw5v49AmVKY_shot_5_8.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/washroom_bedroom_bathroom_Nw5v49AmVKY_shot_5_8.jpg\" style=\"width: 400px;\"/></td>\n",
      "<tr>\n",
      "<td> <img src= \"src/median/athletics_rJltAwvLzGY_shot_6_13.jpg\" style=\"width: 400px;\"/><br>athletics_rJltAwvLzGY_shot_6_13.jpg</td>\n",
      "<td> <img src= \"src/regression/gt/athletics_rJltAwvLzGY_shot_6_13.jpg\" style=\"width: 400px;\"/></td>\n",
      "<td> <img src= \"src/regression/pred/athletics_rJltAwvLzGY_shot_6_13.jpg\" style=\"width: 400px;\"/></td>\n"
     ]
    }
   ],
   "source": [
    "from shutil import copyfile\n",
    "def print_table():\n",
    "    i = 0\n",
    "    for filename in content:\n",
    "        dst = '../../public_html/webpages/nov_20/src/median/'\n",
    "        dest = dst+filename\n",
    "        if not os.path.isfile(dest):\n",
    "            src = '../../../../z/ghassena/GT30sec/median/'+filename\n",
    "            copyfile(src,dest)\n",
    "#             print(\"------------->\",filename)\n",
    "        \n",
    "        print('<tr>')\n",
    "        print('<td> <img src= \"src/median/'+ filename+'\" style=\"width: 400px;\"/><br>'+filename+'</td>')\n",
    "        print('<td> <img src= \"src/regression/gt/'+ filename+'\" style=\"width: 400px;\"/></td>')\n",
    "        print('<td> <img src= \"src/regression/pred/'+ filename+'\" style=\"width: 400px;\"/></td>') \n",
    "print_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
